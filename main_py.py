# -*- coding: utf-8 -*-
"""main.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wyhPARNJO_4XEbaUOzgpUQSoRYT56t_a
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import math
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, recall_score, precision_score, f1_score, roc_auc_score,confusion_matrix
import shap
import numpy as np
from sklearn.metrics import f1_score

CSV_file= pd.read_csv('/content/train.csv')
print(CSV_file.info())
print(CSV_file.describe)

print(CSV_file.head(10))

CSV_file.isnull().sum()

CSV_file.drop(columns=['Churn Category','Churn Reason','Churn Score'],inplace= True)
drop_cols = ['Customer ID', 'City', 'Country', 'Lat Long', 'State', 'Zip Code','CLTV','Customer Status']
CSV_file = CSV_file.drop(columns=drop_cols)

CSV_file['Internet Type'].fillna('No Internet', inplace= True)
CSV_file['Offer'].fillna('No Offer', inplace= True)

CSV_file.isnull().sum()

num_column= CSV_file.select_dtypes(include=['int64','float64'])
col_column= CSV_file.select_dtypes(include=['object'])

plt.figure(figsize=(12, 8))
sns.heatmap(num_column.corr(), annot=True)
plt.show()

binary_cols = [c for c in num_column if CSV_file[c].nunique() == 2 and c != 'Churn']
cont_cols   = [c for c in num_column if CSV_file[c].nunique() > 2 and c != 'Churn']

n = len(binary_cols)
cols = 3
rows = math.ceil(n / cols)
plt.figure(figsize=(16, rows * 4))

for i, col in enumerate(binary_cols, 1):
    plt.subplot(rows, cols, i)
    sns.boxplot(x='Churn', y=col, data=CSV_file)
    plt.title(f"{col} vs Churn")
    plt.tight_layout()

plt.show()

n = len(cont_cols)
cols = 3
rows = math.ceil(n / cols)
plt.figure(figsize=(16, rows * 4))

for i, col in enumerate(cont_cols, 1):
    plt.subplot(rows, cols, i)
    sns.boxplot(x='Churn', y=col, data=CSV_file)
    plt.title(f"{col} vs Churn")
    plt.tight_layout()

plt.show()

X= CSV_file.drop(columns=['Churn'])
y=CSV_file['Churn']

X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2, random_state=42, stratify=y)

for col in col_column:
  le= LabelEncoder()
  X_train[col]= le.fit_transform(X_train[col])
  X_test[col] = le.transform(X_test[col])

import xgboost as xgb

model_xgb = xgb.XGBClassifier(
    max_depth=6,
    learning_rate=0.1,
    n_estimators=300,
    subsample=0.8,
    colsample_bytree=0.8,
    eval_metric='logloss'
)

model_xgb.fit(X_train, y_train)

y_pred= model_xgb.predict(X_test)
y_pred_proba= model_xgb.predict_proba(X_test)[:,1]

print("Accuracy: ", accuracy_score(y_test,y_pred))
print("Precision: ", precision_score(y_test,y_pred))
print("Recall: ", recall_score(y_test,y_pred))
print("F1 Score: ", f1_score(y_test,y_pred))
print("ROC- AUC: ", roc_auc_score(y_test,y_pred))
print("Confusion Matrix: ", confusion_matrix(y_test,y_pred))

xgb.plot_importance(model_xgb)

shap.initjs()
explainer= shap.TreeExplainer(model_xgb)
shap_values= explainer.shap_values(X_test)
plt.figure(figsize=(12, 8))
shap.summary_plot(shap_values, X_test, plot_type="bar")

shap.plots._waterfall.waterfall_legacy(
    explainer.expected_value,
    shap_values[i],
    feature_names=X_test.columns
)

from sklearn.model_selection import  RandomizedSearchCV



param_dist = {
    "n_estimators": [200, 300, 400, 500],
    "max_depth": [3, 4, 5, 6, 8],
    "learning_rate": [0.01, 0.05, 0.1],
    "subsample": [0.6, 0.8, 1.0],
    "colsample_bytree": [0.6, 0.8, 1.0],
    "min_child_weight": [1, 3, 5],
    "gamma": [0, 1, 5],
}

rand_search = RandomizedSearchCV(
    estimator=model_xgb,
    param_distributions=param_dist,
    n_iter=25,
    scoring="f1",
    cv=3,
    verbose=1,
    n_jobs=-1,
    random_state=42
)

rand_search.fit(X_train, y_train)

print("Best parameters found:")
print(rand_search.best_params_)



best_xgb = rand_search.best_estimator_

best_xgb.fit(X_train, y_train)

y_pred = best_xgb.predict(X_test)
y_proba = best_xgb.predict_proba(X_test)[:, 1]

acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc = roc_auc_score(y_test, y_proba)
cm = confusion_matrix(y_test, y_pred)

print("Accuracy: ", acc)
print("Precision:", prec)
print("Recall:   ", rec)
print("F1 Score: ", f1)
print("ROC-AUC:  ", roc)
print("\nConfusion Matrix:\n", cm)
print("\nClassification report:\n", classification_report(y_test, y_pred))
explainer = shap.TreeExplainer(best_xgb)
shap_values = explainer.shap_values(X_test)

plt.figure(figsize=(12, 8))
shap.summary_plot(shap_values, X_test, plot_type="bar", show=False)
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 8))
shap.summary_plot(shap_values, X_test, show=False)
plt.tight_layout()
plt.show()

shap.plots._waterfall.waterfall_legacy(
    explainer.expected_value,
    shap_values[i],
    feature_names=X_test.columns
)

test_csv_file= pd.read_csv('/content/test.csv')
test_csv_file.isnull().sum()

test_csv_file.drop(columns=['Churn Category','Churn Reason','Churn Score'],inplace= True)
drop_cols = ['Customer ID', 'City', 'Country', 'Lat Long', 'State', 'Zip Code','CLTV','Customer Status']
test_csv_file = test_csv_file.drop(columns=drop_cols)

test_csv_file['Internet Type'].fillna('No Internet',inplace= True)
test_csv_file['Offer'].fillna('No Offer',inplace= True)

test_csv_file.isnull().sum()

y_true = test_csv_file["Churn"].copy()

test_csv_file.drop(columns='Churn', inplace = True)

num_column= test_csv_file.select_dtypes(include=['int64','float64'])
obj_column= test_csv_file.select_dtypes(include=['object'])

for col in obj_column.columns:
    test_csv_file[col] = test_csv_file[col].astype("category")

test_df = test_csv_file.copy()
X_new = test_df[X_train.columns]
y_pred_proba = best_xgb.predict_proba(X_new)[:, 1]
y_pred_test = (y_pred_proba > 0.5).astype(int)
test_df["Churn_Prob"] = y_pred_proba
test_df["Churn_Pred"] = y_pred_test
high_risk = test_df.sort_values("Churn_Prob", ascending=False).head(20)
print(high_risk[["Churn_Prob", "Churn_Pred"]])

test_df["Churn_Pred"].value_counts()

print("Accuracy:", accuracy_score(y_true, y_pred))
print("Precision:", precision_score(y_true, y_pred))
print("Recall:", recall_score(y_true, y_pred))
print("F1:", f1_score(y_true, y_pred))
print("ROC-AUC:", roc_auc_score(y_true, y_pred_proba))
print("\nConfusion Matrix:\n", confusion_matrix(y_true, y_pred))

thresholds = np.linspace(0.1, 0.9, 17)

for t in thresholds:
    y_temp = (y_pred_proba > t).astype(int)
    print(f"Threshold: {t:.2f}, F1: {f1_score(y_true, y_temp):.4f}")

test_df = test_csv_file.copy()
X_new = test_df[X_train.columns]

y_pred_proba = best_xgb.predict_proba(X_new)[:, 1]
y_pred_test = (y_pred_proba > 0.45).astype(int)

test_df["Churn_Prob"] = y_pred_proba
test_df["Churn_Pred"] = y_pred_test

high_risk = test_df.sort_values("Churn_Prob", ascending=False).head(20)
print(high_risk[["Churn_Prob", "Churn_Pred"]])

print(test_df["Churn_Pred"].value_counts())

# Evaluate correctly with the new threshold
print("Accuracy:", accuracy_score(y_true, y_pred_test))
print("Precision:", precision_score(y_true, y_pred_test))
print("Recall:", recall_score(y_true, y_pred_test))
print("F1:", f1_score(y_true, y_pred_test))
print("ROC-AUC:", roc_auc_score(y_true, y_pred_proba))
print("\nConfusion Matrix:\n", confusion_matrix(y_true, y_pred_test))

from google.colab import drive
drive.mount('/content/drive')